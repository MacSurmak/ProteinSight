# -*- coding: utf-8 -*-
"""
Trains a 3D U-Net model for binding site prediction using pre-generated caches.

This script implements the complete training and validation pipeline, leveraging
the cluster-based data splits and coordinate caches prepared by the previous
script. It is designed for high performance and robustness.

Key features of the training pipeline:
1.  Loads dataset splits from a JSON file to ensure no data leakage between
    training, validation, and test sets at the cluster level.
2.  Uses a sophisticated DataLoader that implements a balanced sampling strategy:
    - 50/50 ratio of positive to negative examples per batch.
    - Positive examples are generated by selecting a point within the binding
      site and applying a random spatial jitter to the patch center.
    - Negative examples are a mix of "hard negatives" (from distant surfaces
      of positive proteins) and "easy negatives" (from negative control proteins).
3.  Employs a deep 3D U-Net architecture with dropout for regularization.
4.  Utilizes modern PyTorch optimizations for speed: torch.compile, Automatic
    Mixed Precision (AMP), and channels-last memory format.
5.  Implements a combined Dice and MSE loss function, suitable for segmentation
    tasks with class imbalance.
6.  Provides comprehensive monitoring:
    - Saves model checkpoints and the best-performing model.
    - Generates and updates a loss curve plot after each epoch.
    - Creates visualization previews of model predictions on a fixed set of
      validation examples to track learning progress visually.
"""
import json
import random
import warnings
from pathlib import Path
from typing import Dict, List, Tuple

import h5py
import matplotlib
import matplotlib.ticker as mticker
import seaborn as sns
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from rich.console import Console
from rich.progress import track

from model import Deeper3DUnetWithDropout

# Use a non-interactive backend for matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

# Suppress benign warnings for cleaner output
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

# --- Configuration ---
console = Console()

# Input directories and files from previous steps
HDF5_CACHE_ROOT = Path("feature_cache")
NPZ_CACHE_DIR = Path("patch_coordinates_cache/npz_cache")
DATASET_SPLIT_REPORT_CSV = Path("dataset_split_report.csv")

# Output directories
OUTPUT_DIR = Path("unet_training_output")
MODEL_SAVE_PATH = OUTPUT_DIR / "unet_best_model.pth"
CHECKPOINT_PATH = OUTPUT_DIR / "unet_checkpoint.pth"
VISUALIZATION_DIR = OUTPUT_DIR / "epoch_previews"
LOSS_CURVE_PATH = OUTPUT_DIR / "loss_curve.pdf"
LOSS_DATA_CSV_PATH = OUTPUT_DIR / "loss_curve_data.csv"

# --- Data and Model Parameters ---
PATCH_SIZE = 64
NUM_INPUT_CHANNELS = 8
JITTER_RANGE = 32  # Max random offset from binding site center (+/-)
CHANNELS = [
    "occupancy",
    "hydrophobicity",
    "electrostatic",
    "aromatic_field",
    "shape_index",
    "hbond_donor",
    "hbond_acceptor",
    "sasa",
]
CHANNEL_MAP: Dict[str, int] = {name: i for i, name in enumerate(CHANNELS)}

# --- Training Hyperparameters ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 16
LEARNING_RATE = 3e-4
WEIGHT_DECAY = 1e-5
NUM_EPOCHS = 128
STEPS_PER_EPOCH_TRAIN = 256
STEPS_PER_EPOCH_VAL = 64
NUM_WORKERS = 16
RANDOM_SEED = 42


# --- Data Handling ---
class SmartPatchDataset(Dataset):
    """Dataset for generating balanced and jittered 3D patches for training."""

    def __init__(self, pdb_ids_map: Dict[str, List[str]], steps_per_epoch: int):
        self.steps_per_epoch = steps_per_epoch
        self.pos_pdbs = pdb_ids_map.get("positive", [])
        self.neg_pdbs = pdb_ids_map.get("negative", [])
        self.half_patch = PATCH_SIZE // 2

    def __len__(self):
        return self.steps_per_epoch * BATCH_SIZE

    def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:
        while True:
            try:
                is_positive_sample = random.random() < 0.5
                if is_positive_sample:
                    if not self.pos_pdbs:
                        continue
                    pdb_id = random.choice(self.pos_pdbs)
                    npz_path = NPZ_CACHE_DIR / f"{pdb_id}.npz"
                    coords = np.load(npz_path)

                    if coords["hot_coords"].shape[0] == 0:
                        continue
                    target_coord = random.choice(coords["hot_coords"])
                    jitter = np.random.randint(-JITTER_RANGE, JITTER_RANGE + 1, size=3)
                    center_coord = target_coord + jitter

                    h5_path = HDF5_CACHE_ROOT / "positive_cache" / f"{pdb_id}.h5"

                else:  # Negative sample
                    is_hard_negative = random.random() < 0.5 and self.pos_pdbs
                    if is_hard_negative:
                        pdb_id = random.choice(self.pos_pdbs)
                        npz_path = NPZ_CACHE_DIR / f"{pdb_id}.npz"
                        coords = np.load(npz_path)

                        if coords["cold_surface_coords"].shape[0] == 0:
                            continue
                        center_coord = random.choice(coords["cold_surface_coords"])
                        h5_path = HDF5_CACHE_ROOT / "positive_cache" / f"{pdb_id}.h5"
                    else:
                        if not self.neg_pdbs:
                            continue
                        pdb_id = random.choice(self.neg_pdbs)
                        npz_path = NPZ_CACHE_DIR / f"{pdb_id}.npz"
                        coords = np.load(npz_path)

                        if coords["surface_coords"].shape[0] == 0:
                            continue
                        center_coord = random.choice(coords["surface_coords"])
                        h5_path = HDF5_CACHE_ROOT / "negative_cache" / f"{pdb_id}.h5"

                with h5py.File(h5_path, "r") as f:
                    features = f["features"]
                    target = f["target_mask"]
                    dims = np.array(features.shape[1:])

                    z_c, y_c, x_c = np.clip(
                        center_coord, self.half_patch, dims - self.half_patch - 1
                    )

                    input_patch = features[
                        :,
                        z_c - self.half_patch : z_c + self.half_patch,
                        y_c - self.half_patch : y_c + self.half_patch,
                        x_c - self.half_patch : x_c + self.half_patch,
                    ]
                    target_patch = target[
                        z_c - self.half_patch : z_c + self.half_patch,
                        y_c - self.half_patch : y_c + self.half_patch,
                        x_c - self.half_patch : x_c + self.half_patch,
                    ]

                input_tensor = torch.from_numpy(input_patch.astype(np.float32))
                target_tensor = torch.from_numpy(
                    target_patch.astype(np.float32)
                ).unsqueeze(0)

                # Data Augmentation
                if random.random() > 0.5:
                    input_tensor, target_tensor = torch.flip(
                        input_tensor, [1]
                    ), torch.flip(target_tensor, [1])
                if random.random() > 0.5:
                    input_tensor, target_tensor = torch.flip(
                        input_tensor, [2]
                    ), torch.flip(target_tensor, [2])
                if random.random() > 0.5:
                    input_tensor, target_tensor = torch.flip(
                        input_tensor, [3]
                    ), torch.flip(target_tensor, [3])

                return input_tensor, target_tensor
            except Exception:
                continue


# --- Loss and Visualization ---
class DiceLoss(nn.Module):
    def __init__(self, smooth=1e-6):
        super().__init__()
        self.smooth = smooth

    def forward(self, outputs, targets):
        outputs = torch.sigmoid(outputs).view(-1)
        targets = targets.view(-1)
        intersection = (outputs * targets).sum()
        return 1 - (2.0 * intersection + self.smooth) / (
            outputs.sum() + targets.sum() + self.smooth
        )


class CombinedLoss(nn.Module):
    def __init__(self, dice_weight=0.6, mse_weight=0.4):
        super().__init__()
        self.dice = DiceLoss()
        self.mse = nn.MSELoss()
        self.dice_w, self.mse_w = dice_weight, mse_weight

    def forward(self, outputs, targets):
        return self.dice_w * self.dice(outputs, targets) + self.mse_w * self.mse(
            torch.sigmoid(outputs), targets
        )


def get_patch_from_center(
    h5_path: Path, center_coord: np.ndarray
) -> Tuple[torch.Tensor, torch.Tensor]:
    """Extracts a patch from an HDF5 file given a center coordinate."""
    with h5py.File(h5_path, "r") as f:
        features, target = f["features"][:], f["target_mask"][:]

    half = PATCH_SIZE // 2
    dims = np.array(features.shape[1:])
    z, y, x = np.clip(center_coord, half, dims - half - 1)

    input_patch = features[
        :, z - half : z + half, y - half : y + half, x - half : x + half
    ]
    target_patch = target[z - half : z + half, y - half : y + half, x - half : x + half]

    return torch.from_numpy(input_patch), torch.from_numpy(target_patch).unsqueeze(0)


def visualize_prediction(
    input_p, target_p, predicted_p, epoch, save_dir, pdb_id, sample_type
):
    inp_np = input_p.cpu().numpy().astype(np.float32)
    tgt_np = target_p.squeeze(0).cpu().numpy()
    prd_np = torch.sigmoid(predicted_p).squeeze(0).squeeze(0).cpu().numpy()

    rgb_input = np.stack(
        [
            inp_np[CHANNEL_MAP["sasa"]],
            (inp_np[CHANNEL_MAP["hydrophobicity"]] + 1) / 2,
            (inp_np[CHANNEL_MAP["electrostatic"]] + 1) / 2,
        ],
        axis=-1,
    )
    rgb_input = np.clip(rgb_input, 0, 1)

    c = PATCH_SIZE // 2
    sns.set_theme(style="white", context="paper")
    fig, axes = plt.subplots(1, 3, figsize=(6, 2.2), constrained_layout=True)

    axes[0].imshow(rgb_input[c, :, :], origin="lower")
    axes[0].set_title("Input (R: SASA, G: HYD, B: ELEC)", fontsize=8)
    axes[1].imshow(tgt_np[c, :, :], cmap="hot", origin="lower", vmin=0, vmax=1)
    axes[1].set_title("Target Mask", fontsize=8)
    im = axes[2].imshow(prd_np[c, :, :], cmap="hot", origin="lower", vmin=0, vmax=1)
    axes[2].set_title("Prediction", fontsize=8)

    cbar = fig.colorbar(im, ax=axes[2], shrink=0.8, aspect=10)
    cbar.ax.tick_params(labelsize=6)
    cbar.set_ticks([0, 0.5, 1.0])

    for ax in axes:
        ax.tick_params(axis="both", which="both", length=0, labelbottom=False, labelleft=False)

    save_dir.mkdir(exist_ok=True, parents=True)
    plt.savefig(save_dir / f"epoch_{epoch + 1:04d}.pdf", bbox_inches='tight')
    plt.close(fig)


def plot_loss_curves(train_losses, val_losses, save_path, csv_save_path):
    """
    Plots training and validation loss curves and saves the plot and raw data.
    The x-axis is configured to show integer epochs starting from 0.
    """

    if not train_losses or not val_losses:
        return

    epochs = range(1, len(train_losses) + 1)

    df = pd.DataFrame({
        'epoch': epochs,
        'train_loss': train_losses,
        'val_loss': val_losses
    })
    df.to_csv(csv_save_path, index=False, float_format='%.6f')

    sns.set_theme(style="ticks", context="paper")
    fig, ax = plt.subplots(figsize=(4, 3))

    ax.plot(epochs, train_losses, label="Training Loss", color="black", linewidth=1.5)
    ax.plot(epochs, val_losses, label="Validation Loss", color="red", linestyle="--", linewidth=1.5)

    ax.set_xlabel("Epoch", fontsize=10)
    ax.set_ylabel("Loss (Dice + MSE)", fontsize=10)
    
    ax.set_xlim(left=1, right=len(train_losses))

    ax.xaxis.set_major_locator(mticker.MaxNLocator(integer=True))
    
    ax.legend(fontsize=8)
    ax.grid(True, linestyle=":", alpha=0.6)
    ax.tick_params(axis='both', which='major', labelsize=8)
    
    sns.despine(ax=ax)

    output_pdf_path = save_path.with_suffix('.pdf')
    plt.savefig(output_pdf_path, bbox_inches='tight')
    plt.close(fig)


# --- Main Execution ---
def main():
    if RANDOM_SEED:
        random.seed(RANDOM_SEED)
        np.random.seed(RANDOM_SEED)
        torch.manual_seed(RANDOM_SEED)
    if DEVICE == "cuda":
        torch.set_float32_matmul_precision("high")

    console.rule(f"[bold blue]Starting U-Net Training on {DEVICE}[/bold blue]")
    OUTPUT_DIR.mkdir(exist_ok=True)
    VISUALIZATION_DIR.mkdir(exist_ok=True)

    split_report_df = pd.read_csv(DATASET_SPLIT_REPORT_CSV)
    console.print(f"Loaded split report with {len(split_report_df)} total entries.")

    existing_npz_files = {p.stem for p in NPZ_CACHE_DIR.glob("*.npz")}
    
    console.print(f"Found {len(existing_npz_files)} existing .npz cache files.")

    filtered_df = split_report_df[split_report_df['pdb_id'].isin(existing_npz_files)].copy()
    
    console.print(f"Using {len(filtered_df)} entries that have a corresponding cache file.")

    train_df = filtered_df[filtered_df['split'] == 'train']
    val_df = filtered_df[filtered_df['split'] == 'validation']

    train_pdb_ids = {
        "positive": train_df[train_df['group'] == 'positive']['pdb_id'].tolist(),
        "negative": train_df[train_df['group'] == 'negative']['pdb_id'].tolist(),
    }
    
    val_pdb_ids = {
        "positive": val_df[val_df['group'] == 'positive']['pdb_id'].tolist(),
        "negative": val_df[val_df['group'] == 'negative']['pdb_id'].tolist(),
    }

    # --- DEBUG ---
    console.rule("[bold yellow]Debug: Visualizing Split Distribution[/bold yellow]")
    
    def visualize_split_distribution(df: pd.DataFrame, output_dir: Path):
        """Creates a bar plot showing the number of unique clusters per split."""
        cluster_counts = df.groupby(['split', 'group'])['cluster_id'].nunique().reset_index()
        
        fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)
        sns.set_theme(style="whitegrid", context="paper")
        
        groups = ['positive', 'negative']
        colors = ['#34A853', '#EA4335']
        
        for i, group in enumerate(groups):
            ax = axes[i]
            data = cluster_counts[cluster_counts['group'] == group]
            
            sns.barplot(
                x='split', 
                y='cluster_id', 
                data=data, 
                ax=ax, 
                order=['train', 'validation', 'test'],
                palette=f"dark:{colors[i]}",
                hue='split',
                legend=False
            )
            ax.set_title(f"{group.capitalize()} Group", fontsize=10)
            ax.set_ylabel("Number of Unique Clusters" if i == 0 else "", fontsize=12)
            ax.tick_params(axis='x', rotation=45, labelsize=9)
            ax.tick_params(axis='y', labelsize=9)

            # Add count labels on top of bars
            for p in ax.patches:
                ax.annotate(f'{int(p.get_height())}', 
                            (p.get_x() + p.get_width() / 2., p.get_height()), 
                            ha='center', va='center', 
                            xytext=(0, 5), 
                            textcoords='offset points',
                            fontsize=8)

        plt.tight_layout(rect=[0, 0, 1, 0.96])
        
        viz_path = output_dir / "split_distribution_report.pdf"
        plt.savefig(viz_path)
        plt.close(fig)
        console.print(f"Split distribution visualization saved to [cyan]{viz_path}[/cyan]")

    # Generate the visualization using the dataframe we already loaded
    visualize_split_distribution(split_report_df, OUTPUT_DIR)
    console.rule()
    # --- DEBUG ---

    train_dataset = SmartPatchDataset(train_pdb_ids, STEPS_PER_EPOCH_TRAIN)

    train_dataset = SmartPatchDataset(train_pdb_ids, STEPS_PER_EPOCH_TRAIN)
    val_dataset = SmartPatchDataset(val_pdb_ids, STEPS_PER_EPOCH_VAL)

    train_loader = DataLoader(
        train_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=NUM_WORKERS,
        pin_memory=True,
        persistent_workers=(NUM_WORKERS > 0),
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        num_workers=NUM_WORKERS,
        pin_memory=True,
        persistent_workers=(NUM_WORKERS > 0),
    )

    console.rule("[bold]Preparing Visualization Samples[/bold]")
    viz_samples = {}

    viz_pdbs_pos = random.sample(
        val_pdb_ids["positive"], min(2, len(val_pdb_ids["positive"]))
    )
    for pdb_id in viz_pdbs_pos:
        npz_path = NPZ_CACHE_DIR / f"{pdb_id}.npz"
        h5_path = HDF5_CACHE_ROOT / "positive_cache" / f"{pdb_id}.h5"
        coords = np.load(npz_path)
        if coords["hot_coords"].shape[0] > 0:
            center = coords["hot_coords"].mean(axis=0).astype(int)
            inp, tgt = get_patch_from_center(h5_path, center)
            viz_samples[f"{pdb_id}_pos"] = (inp, tgt, "positive")

    viz_pdbs_hard_neg = random.sample(
        val_pdb_ids["positive"], min(2, len(val_pdb_ids["positive"]))
    )
    for pdb_id in viz_pdbs_hard_neg:
        npz_path = NPZ_CACHE_DIR / f"{pdb_id}.npz"
        h5_path = HDF5_CACHE_ROOT / "positive_cache" / f"{pdb_id}.h5"
        coords = np.load(npz_path)
        if coords["cold_surface_coords"].shape[0] > 0:
            center = random.choice(coords["cold_surface_coords"])
            inp, tgt = get_patch_from_center(h5_path, center)
            viz_samples[f"{pdb_id}_neg_hard"] = (inp, tgt, "neg-hard")

    viz_pdbs_easy_neg = random.sample(
        val_pdb_ids["negative"], min(2, len(val_pdb_ids["negative"]))
    )
    for pdb_id in viz_pdbs_easy_neg:
        npz_path = NPZ_CACHE_DIR / f"{pdb_id}.npz"
        h5_path = HDF5_CACHE_ROOT / "negative_cache" / f"{pdb_id}.h5"
        coords = np.load(npz_path)
        if coords["surface_coords"].shape[0] > 0:
            center = random.choice(coords["surface_coords"])
            inp, tgt = get_patch_from_center(h5_path, center)
            viz_samples[f"{pdb_id}_neg_easy"] = (inp, tgt, "neg-easy")

    console.print("Visualization samples prepared:", list(viz_samples.keys()))

    model = Deeper3DUnetWithDropout(NUM_INPUT_CHANNELS, 1).to(
        DEVICE, memory_format=torch.channels_last_3d
    )
    model = torch.compile(model)

    criterion = CombinedLoss()
    optimizer = optim.AdamW(
        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY
    )
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, "min", factor=0.2, patience=15
    )
    scaler = torch.amp.GradScaler("cuda", enabled=(DEVICE == "cuda"))

    start_epoch, best_val_loss = 0, float("inf")
    train_losses, val_losses = [], []

    if CHECKPOINT_PATH.exists():
        console.print(f"--- Resuming from checkpoint: {CHECKPOINT_PATH} ---")
        ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE)
        model.load_state_dict(ckpt["model_state_dict"])
        optimizer.load_state_dict(ckpt["optimizer_state_dict"])
        scheduler.load_state_dict(ckpt["scheduler_state_dict"])
        scaler.load_state_dict(ckpt["scaler_state_dict"])
        start_epoch = ckpt["epoch"] + 1
        best_val_loss = ckpt.get("best_val_loss", float("inf"))
        train_losses, val_losses = ckpt.get("train_losses", []), ckpt.get(
            "val_losses", []
        )

    for epoch in range(start_epoch, NUM_EPOCHS):
        console.rule(f"Epoch {epoch + 1}/{NUM_EPOCHS}")

        model.train()
        epoch_train_loss = 0.0
        for inputs, targets in track(train_loader, description="Training"):
            inputs = inputs.to(
                DEVICE, non_blocking=True, memory_format=torch.channels_last_3d
            )
            targets = targets.to(DEVICE, non_blocking=True)
            optimizer.zero_grad(set_to_none=True)
            with torch.amp.autocast("cuda", enabled=(DEVICE == "cuda")):
                outputs = model(inputs)
                loss = criterion(outputs, targets)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            epoch_train_loss += loss.item()
        avg_train_loss = epoch_train_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        model.eval()
        epoch_val_loss = 0.0
        with torch.no_grad():
            for inputs, targets in track(val_loader, description="Validating"):
                inputs = inputs.to(
                    DEVICE, non_blocking=True, memory_format=torch.channels_last_3d
                )
                targets = targets.to(DEVICE, non_blocking=True)
                with torch.amp.autocast("cuda", enabled=(DEVICE == "cuda")):
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
                epoch_val_loss += loss.item()
        avg_val_loss = epoch_val_loss / len(val_loader)
        val_losses.append(avg_val_loss)
        scheduler.step(avg_val_loss)

        console.print(
            f"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.2e}"
        )

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            state_dict_to_save = (
                model._orig_mod.state_dict()
                if hasattr(model, "_orig_mod")
                else model.state_dict()
            )
            torch.save(state_dict_to_save, MODEL_SAVE_PATH)
            console.print(f"  [green]New best model saved to {MODEL_SAVE_PATH}[/green]")

        state_dict_to_save = (
            model._orig_mod.state_dict()
            if hasattr(model, "_orig_mod")
            else model.state_dict()
        )
        torch.save(
            {
                "epoch": epoch,
                "model_state_dict": state_dict_to_save,
                "optimizer_state_dict": optimizer.state_dict(),
                "scheduler_state_dict": scheduler.state_dict(),
                "scaler_state_dict": scaler.state_dict(),
                "best_val_loss": best_val_loss,
                "train_losses": train_losses,
                "val_losses": val_losses,
            },
            CHECKPOINT_PATH,
        )

        with torch.no_grad():
            for sample_key, (viz_in, viz_tgt, sample_type) in viz_samples.items():
                viz_in_gpu = viz_in.unsqueeze(0).to(
                    DEVICE, memory_format=torch.channels_last_3d
                )
                with torch.amp.autocast("cuda", enabled=(DEVICE == "cuda")):
                    pred_viz = model(viz_in_gpu)
                pdb_id_only = sample_key.split("_")[0]
                visualize_prediction(
                    viz_in,
                    viz_tgt,
                    pred_viz.squeeze(0),
                    epoch,
                    VISUALIZATION_DIR / sample_key,
                    pdb_id_only,
                    sample_type,
                )

        plot_loss_curves(train_losses, val_losses, LOSS_CURVE_PATH, LOSS_DATA_CSV_PATH)

    console.rule("[bold green]Training Complete[/bold green]")


if __name__ == "__main__":
    main()
